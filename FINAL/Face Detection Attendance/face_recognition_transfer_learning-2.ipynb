{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nNDpiUVi_k9h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLl0Wb3w_k9j",
        "outputId": "43dbfdc9-c5f4-4bd4-f2f3-a2a2d957f871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "training_data_path = '/content/drive/MyDrive/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "842UgMI5_k9n"
      },
      "source": [
        "#HEIC to JPG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-UB9OBF_k9o",
        "outputId": "cfb08630-5473-4f23-adbb-d5b622a6adcb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pillow-heif in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pillow>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from pillow-heif) (11.3.0)\n",
            "\n",
            "Total converted: 0 HEIC files\n"
          ]
        }
      ],
      "source": [
        "# Install pillow-heif to handle HEIC files\n",
        "!pip install pillow-heif\n",
        "\n",
        "# Convert all HEIC to JPG\n",
        "from PIL import Image\n",
        "from pillow_heif import register_heif_opener\n",
        "import os\n",
        "\n",
        "register_heif_opener()  # Enable HEIC support\n",
        "\n",
        "converted = 0\n",
        "for root, dirs, files in os.walk(training_data_path):\n",
        "    for file in files:\n",
        "        if file.lower().endswith('.heic'):\n",
        "            heic_path = os.path.join(root, file)\n",
        "            jpg_path = heic_path.rsplit('.', 1)[0] + '.jpg'\n",
        "\n",
        "            try:\n",
        "                img = Image.open(heic_path)\n",
        "                img.convert('RGB').save(jpg_path, 'JPEG')\n",
        "                os.remove(heic_path)  # Delete original HEIC\n",
        "                converted += 1\n",
        "                print(f\"Converted: {file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed: {file} - {e}\")\n",
        "\n",
        "print(f\"\\nTotal converted: {converted} HEIC files\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy dataset to Colab local storage (fast)\n",
        "import shutil\n",
        "\n",
        "print(\"Copying dataset to local storage...\")\n",
        "local_path = '/content/dataset'\n",
        "\n",
        "if os.path.exists(local_path):\n",
        "    shutil.rmtree(local_path)\n",
        "\n",
        "shutil.copytree(training_data_path, local_path)\n",
        "print(f\"Dataset copied to {local_path}\")\n",
        "\n",
        "# Update path\n",
        "training_data_path = local_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MA4l8vWEegN",
        "outputId": "b5e14d62-0063-47d0-822c-0e022b760a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying dataset to local storage...\n",
            "✓ Dataset copied to /content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBVjMSly_k9p",
        "outputId": "6c464bd7-dc51-45c2-d7ea-4a4899475a8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1424 images belonging to 91 classes.\n",
            "Found 340 images belonging to 91 classes.\n",
            "Number of classes: 91\n",
            "Training images: 1424\n",
            "Validation images: 340\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# No augmentation for validation\n",
        "val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Training generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    training_data_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation generator\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    training_data_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "num_classes = len(train_generator.class_indices)\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Training images: {train_generator.samples}\")\n",
        "print(f\"Validation images: {test_generator.samples}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA6MSJX1_k9r"
      },
      "source": [
        "# Person Name Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "f2zUmY2D_k9s"
      },
      "outputs": [],
      "source": [
        "results_map = {v: k for k, v in train_generator.class_indices.items()}\n",
        "\n",
        "with open('results_map.pkl', 'wb') as f:\n",
        "    pickle.dump(results_map, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model"
      ],
      "metadata": {
        "id": "ptuwCyKfCVO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nG3BVsaCWW_",
        "outputId": "945f96b6-803d-4e8a-ed3e-6774445a98fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTGF2_Zy_k9u"
      },
      "source": [
        "#Freezed Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QFbQ-nW_k9u",
        "outputId": "174df80a-48dd-489c-8e80-c0fdce4a3d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 12s/step - accuracy: 0.0719 - loss: 4.5157 - val_accuracy: 0.3214 - val_loss: 3.3403\n",
            "Epoch 2/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 10s/step - accuracy: 0.2562 - loss: 3.4205 - val_accuracy: 0.4935 - val_loss: 2.5995\n",
            "Epoch 3/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 10s/step - accuracy: 0.3755 - loss: 2.7554 - val_accuracy: 0.6169 - val_loss: 1.9433\n",
            "Epoch 4/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 9s/step - accuracy: 0.4715 - loss: 2.2770 - val_accuracy: 0.7500 - val_loss: 1.5204\n",
            "Epoch 5/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 9s/step - accuracy: 0.6019 - loss: 1.7049 - val_accuracy: 0.8052 - val_loss: 1.1685\n",
            "Epoch 6/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 10s/step - accuracy: 0.6431 - loss: 1.5704 - val_accuracy: 0.8279 - val_loss: 0.9608\n",
            "Epoch 7/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 9s/step - accuracy: 0.7451 - loss: 1.1823 - val_accuracy: 0.8409 - val_loss: 0.7929\n",
            "Epoch 8/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 10s/step - accuracy: 0.7691 - loss: 1.0282 - val_accuracy: 0.8701 - val_loss: 0.6624\n",
            "Epoch 9/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 9s/step - accuracy: 0.7915 - loss: 0.9146 - val_accuracy: 0.8766 - val_loss: 0.6116\n",
            "Epoch 10/10\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 9s/step - accuracy: 0.7941 - loss: 0.8499 - val_accuracy: 0.9058 - val_loss: 0.5343\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=10\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEKb8FZN_k9v"
      },
      "source": [
        "# Unfreezed Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKuFauYG_k9v",
        "outputId": "d2b3a232-11b6-4acf-a3c9-7024e2d8f515"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 12s/step - accuracy: 0.7049 - loss: 1.2081 - val_accuracy: 0.7305 - val_loss: 0.9801\n",
            "Epoch 2/5\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 9s/step - accuracy: 0.8690 - loss: 0.5286 - val_accuracy: 0.7500 - val_loss: 0.8603\n",
            "Epoch 3/5\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 9s/step - accuracy: 0.9098 - loss: 0.3823 - val_accuracy: 0.8214 - val_loss: 0.5846\n",
            "Epoch 4/5\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 9s/step - accuracy: 0.9282 - loss: 0.3105 - val_accuracy: 0.8929 - val_loss: 0.3669\n",
            "Epoch 5/5\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 9s/step - accuracy: 0.9485 - loss: 0.2269 - val_accuracy: 0.9221 - val_loss: 0.2883\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "\n",
        "for layer in base_model.layers[:50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "fine_tune_history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=test_generator,\n",
        "    epochs=5\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0NOiVja_k9v"
      },
      "source": [
        "# Evals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKzdGQJ9_k9w",
        "outputId": "b81594a7-63bc-4da1-81b7-c406bae520e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5s/step - accuracy: 0.9161 - loss: 0.2907\n",
            "Test accuracy: 92.21%\n"
          ]
        }
      ],
      "source": [
        "final_loss, final_accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {final_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "i6TXhUaGDOtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('face_recognition_transfer_learning.keras')\n",
        "model.save('face_recognition_transfer_learning.h5')\n",
        "\n",
        "print(\"Model saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjBenJ4mDRkR",
        "outputId": "1fe41ee8-2928-4af1-8de1-ae98efdcce44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model properly\n",
        "model.save('face_recognition_transfer_learning.keras', save_format='keras')\n",
        "\n",
        "# Verify it loads\n",
        "test_model = tf.keras.models.load_model('face_recognition_transfer_learning.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2REQmLvPSGGO",
        "outputId": "d6fb5e7e-f500-47af-ab7f-57c25f5fb82e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 6 variables whereas the saved optimizer has 2 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}